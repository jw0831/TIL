{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy를 대체하면서 GPU를 이용한 연산이 필요한 경우  \n",
    "최대한의 유연성과 속도를 제공하는 딥러닝 연구 플랫폼이 필요한경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.4013e-44, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "# 초기화되지 않은 5*3 행렬을 생성합니다.\n",
    "x = torch.empty(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5578, 0.6142, 0.7824],\n",
      "        [0.6417, 0.8194, 0.6034],\n",
      "        [0.2622, 0.8265, 0.8133],\n",
      "        [0.3785, 0.0886, 0.0868],\n",
      "        [0.8820, 0.8750, 0.6117]])\n"
     ]
    }
   ],
   "source": [
    "# 무작위로 초기화된 행렬을 생성\n",
    "x = torch.rand(5,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "# dtype이 long이고 0으로 채워진 행렬을 생성합니다.\n",
    "x= torch.zeros(5,3, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "# data로부터 tensor를 직접 생성합니다.\n",
    "x = torch.tensor([5.5, 3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([[-0.0756, -0.5940, -1.5996],\n",
      "        [-0.4299,  0.7222,  0.3450],\n",
      "        [-0.2256,  0.5640, -0.2024],\n",
      "        [ 0.6643, -0.3590, -0.6236],\n",
      "        [-0.5927, -1.8272,  1.1541]])\n"
     ]
    }
   ],
   "source": [
    "# 또는 기존 tensor를 바탕으로 새로운 tensor를 만든다.\n",
    "# 이들 메소드(method)는 사용자로부터 새로운 값을 제공받지 않은 한, \n",
    "# 입력 tensor의 속성들 (예, dtype)을 재사용합니다.\n",
    "\n",
    "x = x.new_ones(5,3, dtype=torch.double) #new_* 메소드는 크기를 받습니다.\n",
    "print(x)\n",
    "\n",
    "x = torch.randn_like(x, dtype = torch.float) #dtype을 오버라이드(Override)합니다. 결과는 동일한 크기를 갖습니다.\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "# 행렬의 크기를 구합니다\n",
    "print(x.size()) # 튜플 타입으로 모든 튜플 연산을 지원한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 연산 (Operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3200, -0.1455, -1.4559],\n",
      "        [ 0.3504,  1.2437,  0.4836],\n",
      "        [-0.2042,  0.6423,  0.2927],\n",
      "        [ 0.8196,  0.6282, -0.3058],\n",
      "        [ 0.1972, -0.9400,  1.3766]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand(5,3)\n",
    "# 방법1\n",
    "print(x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3200, -0.1455, -1.4559],\n",
       "        [ 0.3504,  1.2437,  0.4836],\n",
       "        [-0.2042,  0.6423,  0.2927],\n",
       "        [ 0.8196,  0.6282, -0.3058],\n",
       "        [ 0.1972, -0.9400,  1.3766]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 방법2\n",
    "torch.add(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3200, -0.1455, -1.4559],\n",
      "        [ 0.3504,  1.2437,  0.4836],\n",
      "        [-0.2042,  0.6423,  0.2927],\n",
      "        [ 0.8196,  0.6282, -0.3058],\n",
      "        [ 0.1972, -0.9400,  1.3766]])\n"
     ]
    }
   ],
   "source": [
    "# 덧샘 결과를 토치 인자로 제공\n",
    "result = torch.empty(5,3)\n",
    "torch.add(x,y, out = result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3200, -0.1455, -1.4559],\n",
      "        [ 0.3504,  1.2437,  0.4836],\n",
      "        [-0.2042,  0.6423,  0.2927],\n",
      "        [ 0.8196,  0.6282, -0.3058],\n",
      "        [ 0.1972, -0.9400,  1.3766]])\n"
     ]
    }
   ],
   "source": [
    "# 덧셈: 바꿔치기(in-place) 방식\n",
    "# y에 x 더하기\n",
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5940,  0.7222,  0.5640, -0.3590, -1.8272])\n"
     ]
    }
   ],
   "source": [
    "print(x[:,1]) # 넘파이 스러운 방식으로 1열 프린트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0756, -0.5940, -1.5996],\n",
      "        [-0.4299,  0.7222,  0.3450],\n",
      "        [-0.2256,  0.5640, -0.2024],\n",
      "        [ 0.6643, -0.3590, -0.6236],\n",
      "        [-0.5927, -1.8272,  1.1541]])\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "# 크기 변경: tensor의 크기(size)나 모양(shape)을 변경하고 싶다면 torch.view를 사용\n",
    "x = torch.randn(4,4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8) # -1은 다른 차원에서 유추합니다.\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3418])\n",
      "0.34175342321395874\n"
     ]
    }
   ],
   "source": [
    "# 만약 tensor에 하나의 값만 존재한다면, .item()을 사용하면 숫자 값을 얻을 수 있습니다.\n",
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전치(transposing), 인덱싱(indexing), 슬라이싱(slicing), 수학 계산, 선형 대수, 난수(random number) 등, 100가지 이상의 Tensor 연산은 [여기](https://pytorch.org/docs/stable/torch.html) 에서 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 넘파이 변환\n",
    "Torch Tensor를 NumPy 배열(array)로 변환하거나, 그 반대로 하는 것은 매우 쉽습니다.\n",
    "\n",
    "(Torch Tensor가 CPU 상에 있다면) Torch Tensor와 NumPy 배열은 메모리 공간을 공유하기 때문에, 하나를 변경하면 다른 하나도 변경됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "# Torch Tensor를 NumPy 배열(array)로 변환\n",
    "a = torch.ones(5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "# NumPy 배열의 값이 어떻게 변하는지 확인해보세요.\n",
    "a.add_(1)\n",
    "print(a) # 토치를 변경\n",
    "print(b) # 넘파이도 동시에 변경됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# NumPy 배열을 Torch Tensor로 변환하기\n",
    "# np (NumPy) 배열을 변경하면 Torch Tensor의 값도 자동 변경되는 것을 확인해보세요.\n",
    "\n",
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)\n",
    "# CharTensor를 제외한 CPU 상의 모든 Tensor는 NumPy로 변환할 수 있고, (NumPy에서 Tensor로의) 반대 변환도 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA Tensors\n",
    "# .to 메소드를 사용하여 Tensor를 어떠한 장치로도 옮길 수 있습니다.\n",
    "\n",
    "# 이 코드는 CUDA가 사용 가능한 환경에서만 실행합니다.\n",
    "# ``torch.device`` 를 사용하여 tensor를 GPU 안팎으로 이동해보겠습니다.\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # CUDA 장치 객체(device object)로\n",
    "    y = torch.ones_like(x, device=device)  # GPU 상에 직접적으로 tensor를 생성하거나\n",
    "    x = x.to(device)                       # ``.to(\"cuda\")`` 를 사용하면 됩니다.\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # ``.to`` 는 dtype도 함께 변경합니다!\n",
    "    \n",
    "# 맥은 결과가 안나온다.. cuda지원 안하네?    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

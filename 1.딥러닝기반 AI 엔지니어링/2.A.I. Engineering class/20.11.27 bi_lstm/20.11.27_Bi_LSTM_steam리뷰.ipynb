{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"20.11.27_Bi_LSTM_steam리뷰.ipynb","private_outputs":true,"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyPgPOGAmLnkGLC7IbHZnUDP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Qgi87wtPB6ez"},"source":["### Bidirectional LSTM\n","https://towardsdatascience.com/understanding-bidirectional-rnn-in-pytorch-5bd25a5dd66\n","\n","- 2개의 독립적인 RNN의 결합 (colah's blog 확인)\n","- 문맥을 고려하기위해 역방향으로도 읽어본\n","\n","### Word2Vec\n","- http://jalammar.github.io/illustrated-word2vec/"]},{"cell_type":"code","metadata":{"id":"pnGndskBiQsx"},"source":["!pip install konlpy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jDNDphSRCHdf"},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import urllib.request\n","from collections import Counter\n","from konlpy.tag import Okt\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T_RyULmjCHa-"},"source":["urllib.request.urlretrieve(\"https://raw.githubusercontent.com/bab2min/corpus/master/sentiment/steam.txt\", filename=\"steam.txt\") "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MBWoqutzCHYT"},"source":["total_data = pd.read_table('steam.txt', names=['label', 'reviews']) \n","print('전체 리뷰 개수 :',len(total_data))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SW-PgKtZCHVl"},"source":["total_data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4LcgNINCHTJ"},"source":["total_data['reviews'].nunique()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z3aXJqTICHNH"},"source":["total_data['label'].nunique()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"53KXemEGCHCF"},"source":["total_data.drop_duplicates(subset=['reviews'], inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jmoEg0sylclx"},"source":["print('총 샘플의 수 :', len(total_data))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-x8lcIVNlkqu"},"source":["print(total_data.isnull().values.any())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S4_az7iGln1A"},"source":["train_data, test_data = train_test_split(total_data, test_size = 0.25, random_state = 42)\n","print('훈련용 리뷰의 개수 :', len(train_data))\n","print('테스트용 리뷰의 개수 :', len(test_data))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IOFmV3sy4eEn"},"source":["# 데이터가 한쪽으로 치우칠 경우 맞추어줄 필요가 있다.\n","train_data['label'].value_counts().plot(kind = 'bar')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j7rt2YtT5fhW"},"source":["train_data['reviews']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UGiNkZaV5Dhc"},"source":["train_data['reviews'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")  #한글이 아닌것을 제거"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zZQ1PJHX-8Ug"},"source":["train_data['reviews']=train_data['reviews'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")  #한글이 아닌것을 제거"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kg14-Ezu5iQq"},"source":["# 공란을 제거할때는 우선 nan으로 처리한 후 제거\n","train_data['reviews'].replace('', np.nan, inplace=True) \n","print(train_data.isnull().sum()) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Q_ff88S51lY"},"source":["test_data.drop_duplicates(subset = ['reviews'], inplace=True) # 중복 제거\n","test_data['reviews'] = test_data['reviews'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\") # 정규 표현식 수행\n","test_data['reviews'].replace('', np.nan, inplace=True) # 공백은 Null 값으로 변경\n","test_data = test_data.dropna(how='any') # Null 값 제거\n","print('전처리 후 테스트용 샘플의 개수 :',len(test_data))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7ASXg-iH5_qG"},"source":["stopwords = ['도', '는', '다', '의', '가', '이', '은', '한', '에', '하', '고', '을', '를', '인', '듯', '과', '와', '네', '들', '듯', '지', '임', '게', '만', '게임', '겜', '되', '음', '면'] "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o_tWjtgs6UKB"},"source":["okt=Okt()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9rJLN_-F6b-V"},"source":["train_data['tokenized'] = train_data['reviews'].apply(okt.morphs)\n","train_data['tokenized'] = train_data['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])\n","test_data['tokenized'] = test_data['reviews'].apply(okt.morphs)\n","test_data['tokenized'] = test_data['tokenized'].apply(lambda x: [item for item in x if item not in stopwords]) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AcUidIWp7Q5c"},"source":["negative_words = np.hstack(train_data[train_data.label == 0]['tokenized'].values)\n","positive_words = np.hstack(train_data[train_data.label == 1]['tokenized'].values) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qk5yMSk78DQO"},"source":["print(np.shape(negative_words))\n","print(np.shape(positive_words))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7SzW36MN9OZm"},"source":["negative_word_count=Counter(negative_words)\n","negative_word_count.most_common(20)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6e4WefWR-B8w"},"source":["positive_word_count=Counter(positive_words)\n","positive_word_count.most_common(20)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X0Xs3bfh-qy0"},"source":["fig,(ax1,ax2) = plt.subplots(1,2,figsize=(10,5))\n","text_len = train_data[train_data['label']==1]['tokenized'].map(lambda x: len(x))\n","ax1.hist(text_len, color='red')\n","ax1.set_title('Positive Reviews')\n","ax1.set_xlabel('length of samples')\n","ax1.set_ylabel('number of samples')\n","print('긍정 리뷰의 평균 길이 :', np.mean(text_len))\n","\n","text_len = train_data[train_data['label']==0]['tokenized'].map(lambda x: len(x))\n","ax2.hist(text_len, color='blue')\n","ax2.set_title('Negative Reviews')\n","fig.suptitle('Words in texts')\n","ax2.set_xlabel('length of samples')\n","ax2.set_ylabel('number of samples')\n","print('부정 리뷰의 평균 길이 :', np.mean(text_len))\n","plt.show() "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xLYRudlcAZuH"},"source":["X_train = train_data['tokenized'] \n","X_train"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9eY-Q7mcAb-A"},"source":["y_train = train_data['label'].values \n","X_test= test_data['tokenized'].values\n","y_test = test_data['label'].values "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g6VORoqPA9r1"},"source":["tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(X_train) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HrOnr_cvBAY1"},"source":["tokenizer.index_word"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yOoqx4uCBDlj"},"source":["y_train"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nl-aa3V6BMDE"},"source":["total_cnt = len(tokenizer.word_index) # 단어의 수"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HgwsqnavGLux"},"source":["threshold = 2 \n","rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n","total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n","rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합 "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w968sjZlGTuG"},"source":["# tokenizer.word_counts \n","for key, value in tokenizer.word_counts.items(): \n","  total_freq = total_freq + value\n","  # 단어의 등장 빈도수가 threshold보다 작으면 \n","  if(value < threshold):\n","    rare_cnt = rare_cnt + 1 # 희귀 단어 카운트\n","    rare_freq = rare_freq + value #희귀 단어 빈도수 누적"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Av9MDFivGzYt"},"source":["print('단어 집합(vocabulary)의 크기 :',total_cnt)\n","print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n","print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n","print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4jDsAwdHjQ5"},"source":["vocab_size = total_cnt - rare_cnt + 2\n","# 0 번은 패딩, 1번 oov로 사용, 실제 단어는 2번 index부터 부여\n","print('단어 집합의 크기 :',vocab_size)  #사용할 단어의 개수"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zf_kNUFuIeeT"},"source":["# Tokenizer(vocab_size) \n","#31592를 가지고 토큰화 개체 생성 나머지 단어들은 화면에 출력되지 않는다.\n","# option이 있다 : OOV token\n","tokenizer = Tokenizer(vocab_size, oov_token='OOV') #31592개에 포함되지 않는 단어들은 뭘로 할래? 'OOV'로 부탁해~"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WGiepN2RJeQ3"},"source":["tokenizer.fit_on_texts(X_train) # X_train에 대해서 토큰화 진행"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FEMDLKFWJ_Rd"},"source":["tokenizer.index_word"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K7FMV62aKJCV"},"source":["tokenizer.texts_to_sequences(X_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LgyfVSDSLHnS"},"source":["X_train = tokenizer.texts_to_sequences(X_train)\n","X_test = tokenizer.texts_to_sequences(X_test) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HfXW1cRkLwTE"},"source":["print('리뷰의 최대 길이 :',max(len(l) for l in X_train))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wnw8gXWmLzMF"},"source":["map(len, X_train) # X_train[0]~X_train[마지막] 까지 구해짐"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u50KXRhmMfv-"},"source":["print('리뷰의 평균 길이 :',sum(map(len, X_train))/len(X_train))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ChnPjmliMg9q"},"source":["plt.hist([len(s) for s in X_train], bins=50)\n","plt.xlabel('length of samples')\n","plt.ylabel('number of samples')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8gKb8pYyMpT5"},"source":["def below_threshold_len(max_len, nested_list):\n","  \"비율을 구한다.\"\n","  cnt = 0\n","  for s in nested_list:\n","    if(len(s) <= max_len):\n","        cnt = cnt + 1\n","  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))*100))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UIQKDQFqM35t"},"source":["below_threshold_len?\n","max_len = 60\n","below_threshold_len(max_len, X_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Is23ZzNtM_y6"},"source":["# 패딩 작업\n","X_train = pad_sequences(X_train, maxlen = max_len)\n","X_test = pad_sequences(X_test, maxlen = max_len)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3qnQINMsNmXu"},"source":["X_train[1]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3xxGyH2QNos9"},"source":["# 여기까지가 전처리 작업이었다\n","---"]},{"cell_type":"markdown","metadata":{"id":"n0-SH99bN2gB"},"source":["---\n","# 양방향 LSTM 적용 시작"]},{"cell_type":"code","metadata":{"id":"Wswke-mAN7dX"},"source":["import re\n","from keras.layers import Embedding, Dense, LSTM, Bidirectional\n","from keras.models import Sequential\n","from keras.models import load_model\n","from keras.callbacks import EarlyStopping, ModelCheckpoint "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M00EOTP1N-eO"},"source":["model = Sequential()\n","model.add(Embedding(vocab_size, 100)) # vocab_size (31592) -> 100차원 공간으로 임베딩\n","model.add(Bidirectional(LSTM(100)))\n","model.add(Dense(1, activation='sigmoid')) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RG-9F6GXOA4A"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QZbJL_8wODLz"},"source":["# es 와 mc 는 따로 작동함\n","# fitting 할때 early stopping 을 주었음. patience 는 4번\n","es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BAArTK4pO_so"},"source":["# 값이 계속해서 잘 올라가는 것이 확인 될때 그 시점을 저장\n","mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nQMy-iP5PHR0"},"source":["model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n","history = model.fit(X_train, y_train, epochs=15, callbacks=[es, mc], batch_size=256, validation_split=0.2) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xvf_VeOEPbDK"},"source":["# best_model이 코랩 좌측 폴더탭에 생성된것을 확인 후 불러오기\n","loaded_model = load_model('best_model.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M7eMy3oxT1HS"},"source":["loaded_model.evaluate(X_test, y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4eGFBS3_T_mx"},"source":["def sentiment_predict(new_sentence):\n","  new_sentence = re.sub(r'[^ㄱ-ㅎㅏ-ㅣ가-힣 ]','', new_sentence)\n","  new_sentence = okt.morphs(new_sentence) # 토큰화\n","  new_sentence = [word for word in new_sentence if not word in stopwords] # 불용어 제거\n","  encoded = tokenizer.texts_to_sequences([new_sentence]) # 정수 인코딩\n","  pad_new = pad_sequences(encoded, maxlen = max_len) # 패딩\n","  score = float(loaded_model.predict(pad_new)) # 예측\n","  if(score > 0.5):\n","    print(\"{:.2f}% 확률로 긍정 리뷰입니다.\".format(score * 100))\n","  else:\n","    print(\"{:.2f}% 확률로 부정 리뷰입니다.\".format((1 - score) * 100)) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A0qzONgoUOQj"},"source":["sentiment_predict('노잼 ..완전 재미 없음 ㅉㅉ')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kmMBVL4eUQML"},"source":["sentiment_predict('와 정말 재밌다 좋단다')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"09-F-K20Vr12"},"source":[""],"execution_count":null,"outputs":[]}]}
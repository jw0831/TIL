{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20201204.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCqajRABCfIF"
      },
      "source": [
        "pip install konlpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvTIFIhVEP7-"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers, losses, metrics\n",
        "from keras import preprocessing\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import re\n",
        "\n",
        "from konlpy.tag import Okt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sp20yiBSFevz"
      },
      "source": [
        "chatbot_data=pd.read_csv(\"/content/ChatbotData .csv\")\n",
        "chatbot_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2l9EtustF0Hb"
      },
      "source": [
        "question, answer=list(chatbot_data['Q']), list(chatbot_data['A'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CczaiTvsGWVO"
      },
      "source": [
        "len(question)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1_BTS4bGnXj"
      },
      "source": [
        "question = question[:100]\n",
        "answer = answer[:100]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "go5_mgOpG6Ha"
      },
      "source": [
        "for i in range(10):\n",
        "    print('Q : ' + question[i])\n",
        "    print('A : ' + answer[i])\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCXP3FxvJDjt"
      },
      "source": [
        "# 정규 표현식 필터\n",
        "RE_FILTER = re.compile(\"[.,!?\\\"':;~()]\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOM7WVLjHfYY"
      },
      "source": [
        "def pos_tag(sentences): \n",
        "    # KoNLPy 형태소분석기 설정\n",
        "    tagger = Okt()\n",
        "    # 문장 품사 변수 초기화\n",
        "    sentences_pos = [] \n",
        "    for sentence in sentences:   # 하루가 또 가네요.\n",
        "        # 특수기호 제거\n",
        "        sentence = re.sub(RE_FILTER, \"\", sentence)      \n",
        "#형태소 분석 결과를 \" \"로 연결\n",
        "        sentence = \" \".join(tagger.morphs(sentence))\n",
        "        sentences_pos.append(sentence)\n",
        "    return sentences_pos    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNhj_7lLITHc"
      },
      "source": [
        "# 형태소분석 수행\n",
        "question = pos_tag(question)\n",
        "answer = pos_tag(answer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62TkHfBxIXes"
      },
      "source": [
        "answer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ojv14ey3LkFz"
      },
      "source": [
        "# 형태소분석으로 변환된 챗봇 데이터 출력\n",
        "for i in range(10):\n",
        "    print('Q : ' + question[i])\n",
        "    print('A : ' + answer[i])\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psG-XFsmLvkW"
      },
      "source": [
        "# 질문과 대답 문장들을 하나로 합침"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U94TZzcFL7z6"
      },
      "source": [
        "sentences = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eg172RtOL-fG"
      },
      "source": [
        "sentences.extend(question)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4BffQNlMABZ"
      },
      "source": [
        "sentences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YS3ILJ1MGUE"
      },
      "source": [
        "sentences.extend(answer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSoYsJcdMREB"
      },
      "source": [
        "sentences #질문/답변 형태소 분석 결과가 저장됨"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u05XqiBOMSlg"
      },
      "source": [
        "words = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rv7ILgD-Mia2"
      },
      "source": [
        "for sentence in sentences:\n",
        "    for word in sentence.split():\n",
        "        words.append(word)   \n",
        "\n",
        "# 길이가 0인 단어는 삭제\n",
        "words = [word for word in words if len(word) > 0]   \n",
        "\n",
        "# 중복된 단어 삭제\n",
        "words = list(set(words))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UvgQ4FdM3Vi"
      },
      "source": [
        "len(words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEZBYNg2M5lT"
      },
      "source": [
        "PAD = \"<PADDING>\"   # 패딩\n",
        "STA = \"<START>\"     # 시작\n",
        "END = \"<END>\"       # 끝\n",
        "OOV = \"<OOV>\"       # 없는 단어(Out of Vocabulary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zk_T6o27Npgx"
      },
      "source": [
        "# 제일 앞에 태그 단어 삽입\n",
        "words[:0] = [PAD, STA, END, OOV]\n",
        "words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqKf7zovN1Ow"
      },
      "source": [
        "# 단어와 인덱스의 딕셔너리 생성\n",
        "\n",
        "#문장을 인덱스로 변환하여 챗봇 모델에 입력\n",
        "word_to_index = {word: index for index, word in enumerate(words)}\n",
        "\n",
        "#챗봇 모델의 예측 결과인 인덱스를 문장으로 변환\n",
        "index_to_word = {index: word for index, word in enumerate(words)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2OnpW1ASO7O"
      },
      "source": [
        "index_to_word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaKtA4lESaHg"
      },
      "source": [
        "question[0] # \"12시 땡\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDkeobmlTBiG"
      },
      "source": [
        "# \"12시 땡\" => word_to_index => [31, 333, 0, 0, ..., 0]\n",
        "#                         <--- 최대길이를 30으로 설정    --->\n",
        "# 한 문장에서 단어 시퀀스의 최대 개수\n",
        "max_sequences = 30\n",
        "# 데이터 타입\n",
        "ENCODER_INPUT  = 0\n",
        "DECODER_INPUT  = 1\n",
        "DECODER_TARGET = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBDkg3xATzzs"
      },
      "source": [
        "# 문장을 인덱스로 변환\n",
        "def convert_text_to_index(sentences, vocabulary, type): \n",
        "    sentences_index = [] #문장 -> 단어 -> 인덱스 -> 저장\n",
        "\n",
        "    # 모든 문장에 대해서 반복\n",
        "    for sentence in sentences: #sentence = \"12시 땡\"\n",
        "        sentence_index = [] #각각의 문장을 구성하는 단어들에 대한 index가 저장되는 리스트 변수\n",
        "\n",
        "        # 디코더 입력일 경우 맨 앞에 START 태그 추가\n",
        "        if type == DECODER_INPUT:\n",
        "            sentence_index.extend([vocabulary[STA]])\n",
        "\n",
        "        # 문장의 단어들을 띄어쓰기로 분리\n",
        "        for word in sentence.split(): #[12시,땡]\n",
        "            if vocabulary.get(word) is not None:\n",
        "                # 사전에 있는 단어면 해당 인덱스를 추가\n",
        "                sentence_index.extend([vocabulary[word]])                \n",
        "            else: # 사전에 없는 단어면 OOV 인덱스를 추가\n",
        "                sentence_index.extend([vocabulary[OOV]])\n",
        "\n",
        "        # 최대 길이 검사\n",
        "        if type == DECODER_TARGET:\n",
        "            # 디코더 목표일 경우 맨 뒤에 END 태그 추가\n",
        "            if len(sentence_index) >= max_sequences:\n",
        "                sentence_index = sentence_index[:max_sequences-1] + [vocabulary[END]]\n",
        "            else:\n",
        "                sentence_index += [vocabulary[END]]\n",
        "        else:\n",
        "            if len(sentence_index) > max_sequences:\n",
        "                sentence_index = sentence_index[:max_sequences]\n",
        "            \n",
        "        # 최대 길이에 없는 공간은 패딩 인덱스로 채움\n",
        "        sentence_index += (max_sequences - len(sentence_index)) * [vocabulary[PAD]]\n",
        "\n",
        "        \n",
        "        sentences_index.append(sentence_index)\n",
        "\n",
        "    return np.asarray(sentences_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWRA9uk6UGEq"
      },
      "source": [
        "# 인코더 입력 인덱스 변환\n",
        "x_encoder = convert_text_to_index(question, word_to_index, ENCODER_INPUT)\n",
        "# 첫 번째 인코더 입력 출력 (12시 땡)\n",
        "# \"12시 땡\" => convert_text_to_index => [31, 333, 0, 0, ..., 0]\n",
        "x_encoder[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QhxJG2eUYCA"
      },
      "source": [
        "# 디코더 입력 인덱스 변환\n",
        "x_decoder = convert_text_to_index(answer, word_to_index, DECODER_INPUT)\n",
        "\n",
        "# 첫 번째 디코더 입력 출력 (START 하루 가 또 가네요)\n",
        "#                            1    453  222 190  157\n",
        "x_decoder[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSf99iiLalVR"
      },
      "source": [
        "# 디코더 목표 인덱스 변환\n",
        "y_decoder = convert_text_to_index(answer, word_to_index, DECODER_TARGET)\n",
        "\n",
        "# 첫 번째 디코더 목표 출력 (하루 가 또 가네요 END)\n",
        "#                           453  222 190  157  2\n",
        "y_decoder[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frXkntJ5f8nX"
      },
      "source": [
        "len(y_decoder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJZkmfx3a12Q"
      },
      "source": [
        "np.shape(x_encoder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9mLDe5_gXWJ"
      },
      "source": [
        "# 원핫인코딩 초기화\n",
        "one_hot_data = np.zeros((len(y_decoder), max_sequences, len(words)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LFG7oQ-gZ1h"
      },
      "source": [
        "one_hot_data.shape #(100, 30, 454)\n",
        "y_decoder.shape #(100, 30, 454)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIsP9zSYgojO"
      },
      "source": [
        "for i, sequence in enumerate(y_decoder):\n",
        "    print(i,sequence )\n",
        "    print(sequence.shape)\n",
        "\n",
        "#각 단어를 454차원 원핫 벡터로 표현\n",
        "# 0 [[0. 0. 0. ... 0. 0. 1.]  <--단어1\n",
        "#  [0. 0. 0. ... 0. 0. 0.]    <--단어2\n",
        "#  [0. 0. 0. ... 0. 0. 0.]      ...\n",
        "#  ...\n",
        "#  [1. 0. 0. ... 0. 0. 0.]\n",
        "#  [1. 0. 0. ... 0. 0. 0.]\n",
        "#  [1. 0. 0. ... 0. 0. 0.]]    <-단어30"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8GrVHcobIus"
      },
      "source": [
        "\n",
        "\n",
        "# 디코더 목표를 원핫인코딩으로 변환\n",
        "# 학습시 입력은 인덱스이지만, 출력은 원핫인코딩 형식임\n",
        "for i, sequence in enumerate(y_decoder):\n",
        "    for j, index in enumerate(sequence):\n",
        "        one_hot_data[i, j, index] = 1 #원핫 인코딩\n",
        "        #i는 100개 문장, j는 30개 단어, index는 454개 중 1개를 1로 셋팅\n",
        "\n",
        "# 디코더 목표 설정\n",
        "y_decoder = one_hot_data\n",
        "\n",
        "# 첫 번째 디코더 목표 출력\n",
        "y_decoder[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWAuMKa9fVa9"
      },
      "source": [
        "#모델링"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NJ7BagLioEk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRX4IG0YiR7r"
      },
      "source": [
        "#훈련 모델 인코더 정의\n",
        "#훈련 모델 디코더 정의\n",
        "#예측 모델 인코더 정의\n",
        "#예측 모델 디코더 정의\n",
        "#인덱스를 문장으로 변환"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8S5md7YTi4Bz"
      },
      "source": [
        "# 임베딩 벡터 차원\n",
        "embedding_dim = 100\n",
        "\n",
        "# LSTM 히든레이어 차원\n",
        "lstm_hidden_dim = 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHF7r8FEjNJD"
      },
      "source": [
        "len(words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbXgwLQdiqro"
      },
      "source": [
        "#훈련 모델 인코더 정의\n",
        "# 입력 문장의 인덱스 시퀀스를 입력으로 받음\n",
        "encoder_inputs = layers.Input(shape=(None,))\n",
        "\n",
        "# 임베딩 레이어                      454  ->   100\n",
        "encoder_outputs = layers.Embedding(len(words), embedding_dim)(encoder_inputs)\n",
        "\n",
        "# return_state가 True면 상태값 리턴\n",
        "# LSTM은 state_h(hidden state)와 state_c(cell state) 2개의 상태 존재\n",
        "encoder_outputs, state_h, state_c = layers.LSTM(lstm_hidden_dim,\n",
        "                                                dropout=0.1,\n",
        "                                                recurrent_dropout=0.5,\n",
        "                                                return_state=True)(encoder_outputs)\n",
        "\n",
        "# 히든 상태와 셀 상태를 하나로 묶음\n",
        "encoder_states = [state_h, state_c]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3naDV3PEivGn"
      },
      "source": [
        "# 훈련 모델 디코더 정의\n",
        "# 목표 문장의 인덱스 시퀀스를 입력으로 받음\n",
        "decoder_inputs = layers.Input(shape=(None,))\n",
        "\n",
        "# 임베딩 레이어\n",
        "decoder_embedding = layers.Embedding(len(words), embedding_dim)\n",
        "decoder_outputs = decoder_embedding(decoder_inputs)\n",
        "\n",
        "# 인코더와 달리 return_sequences를 True로 설정하여 모든 타임 스텝 출력값 리턴\n",
        "# 모든 타임 스텝의 출력값들을 다음 레이어의 Dense()로 처리하기 위함\n",
        "decoder_lstm = layers.LSTM(lstm_hidden_dim,\n",
        "                           dropout=0.1,\n",
        "                           recurrent_dropout=0.5,\n",
        "                           return_state=True,\n",
        "                           return_sequences=True)\n",
        "\n",
        "# initial_state를 인코더의 상태로 초기화\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_outputs,\n",
        "                                     initial_state=encoder_states)\n",
        "\n",
        "# 단어의 개수만큼 노드의 개수를 설정하여 원핫 형식으로 각 단어 인덱스를 출력\n",
        "decoder_dense = layers.Dense(len(words), activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynIzM2QZkDqs"
      },
      "source": [
        "#--------------------------------------------\n",
        "# 훈련 모델 정의\n",
        "#--------------------------------------------\n",
        "\n",
        "# 입력과 출력으로 함수형 API 모델 생성\n",
        "model = models.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# 학습 방법 설정\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atCyqg3dk3nq"
      },
      "source": [
        "#--------------------------------------------\n",
        "#  예측 모델 인코더 정의\n",
        "#--------------------------------------------\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUyK0tm0lRMN"
      },
      "source": [
        "# 훈련 모델의 인코더 상태를 사용하여 예측 모델 인코더 설정\n",
        "encoder_model = models.Model(encoder_inputs, encoder_states)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQ49Nd8rlU8I"
      },
      "source": [
        "#--------------------------------------------\n",
        "# 예측 모델 디코더 정의\n",
        "#--------------------------------------------\n",
        "\n",
        "# 예측시에는 훈련시와 달리 타임 스텝을 한 단계씩 수행\n",
        "# 매번 이전 디코더 상태를 입력으로 받아서 새로 설정\n",
        "decoder_state_input_h = layers.Input(shape=(lstm_hidden_dim,))\n",
        "decoder_state_input_c = layers.Input(shape=(lstm_hidden_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]    \n",
        "\n",
        "# 임베딩 레이어\n",
        "decoder_outputs = decoder_embedding(decoder_inputs)\n",
        "\n",
        "# LSTM 레이어\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_outputs,\n",
        "                                                 initial_state=decoder_states_inputs)\n",
        "\n",
        "# 히든 상태와 셀 상태를 하나로 묶음\n",
        "decoder_states = [state_h, state_c]\n",
        "\n",
        "# Dense 레이어를 통해 원핫 형식으로 각 단어 인덱스를 출력\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# 예측 모델 디코더 설정\n",
        "decoder_model = models.Model([decoder_inputs] + decoder_states_inputs,\n",
        "                      [decoder_outputs] + decoder_states)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMxXdwnKlkS7"
      },
      "source": [
        "# 인덱스를 문장으로 변환\n",
        "def convert_index_to_text(indexs, vocabulary): \n",
        "    \n",
        "    sentence = ''\n",
        "    \n",
        "    # 모든 문장에 대해서 반복\n",
        "    for index in indexs:\n",
        "        if index == END_INDEX:\n",
        "            # 종료 인덱스면 중지\n",
        "            break;\n",
        "        if vocabulary.get(index) is not None:\n",
        "            # 사전에 있는 인덱스면 해당 단어를 추가\n",
        "            sentence += vocabulary[index]\n",
        "        else:\n",
        "            # 사전에 없는 인덱스면 OOV 단어를 추가\n",
        "            sentence.extend([vocabulary[OOV_INDEX]])\n",
        "            \n",
        "        # 빈칸 추가\n",
        "        sentence += ' '\n",
        "\n",
        "    return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDsHEe8yobFp"
      },
      "source": [
        "# 태그 인덱스\n",
        "PAD_INDEX = 0\n",
        "STA_INDEX = 1\n",
        "END_INDEX = 2\n",
        "OOV_INDEX = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O5cbDSslu6U"
      },
      "source": [
        "# 에폭 반복\n",
        "for epoch in range(20):\n",
        "    print('Total Epoch :', epoch + 1)\n",
        "\n",
        "    # 훈련 시작\n",
        "    history = model.fit([x_encoder, x_decoder],\n",
        "                        y_decoder,\n",
        "                        epochs=100,\n",
        "                        batch_size=64,\n",
        "                        verbose=0)\n",
        "    \n",
        "    # 정확도와 손실 출력\n",
        "    print('accuracy :', history.history['accuracy'][-1])\n",
        "    print('loss :', history.history['loss'][-1])\n",
        "    \n",
        "    # 문장 예측 테스트\n",
        "    # (3 박 4일 놀러 가고 싶다) -> (여행 은 언제나 좋죠)\n",
        "    input_encoder = x_encoder[2].reshape(1, x_encoder[2].shape[0])\n",
        "    input_decoder = x_decoder[2].reshape(1, x_decoder[2].shape[0])\n",
        "    results = model.predict([input_encoder, input_decoder])\n",
        "    \n",
        "    # 결과의 원핫인코딩 형식을 인덱스로 변환\n",
        "    # 1축을 기준으로 가장 높은 값의 위치를 구함\n",
        "    indexs = np.argmax(results[0], 1) \n",
        "    \n",
        "    # 인덱스를 문장으로 변환\n",
        "    sentence = convert_index_to_text(indexs, index_to_word)\n",
        "    print(sentence)\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhoT9HeKlyvc"
      },
      "source": [
        "# 예측을 위한 입력 생성\n",
        "def make_predict_input(sentence):\n",
        "\n",
        "    sentences = []\n",
        "    sentences.append(sentence)\n",
        "    sentences = pos_tag(sentences)\n",
        "    input_seq = convert_text_to_index(sentences, word_to_index, ENCODER_INPUT)\n",
        "    \n",
        "    return input_seq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdVPjGdC6v49"
      },
      "source": [
        "# 텍스트 생성\n",
        "def generate_text(input_seq):\n",
        "    #array([[156, 414,  89, 405, 280, 158,   0,   0,   0,   0,   0,   0,   0,\n",
        "    #      0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
        "    #      0,   0,   0,   0]])\n",
        "    \n",
        "    # 입력을 인코더에 넣어 마지막 상태 구함\n",
        "    states = encoder_model.predict(input_seq)\n",
        "\n",
        "    # 목표 시퀀스 초기화\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    \n",
        "    # 목표 시퀀스의 첫 번째에 <START> 태그 추가\n",
        "    target_seq[0, 0] = STA_INDEX\n",
        "    \n",
        "    # 인덱스 초기화\n",
        "    indexs = []\n",
        "    \n",
        "    # 디코더 타임 스텝 반복\n",
        "    while 1:\n",
        "        # 디코더로 현재 타임 스텝 출력 구함\n",
        "        # 처음에는 인코더 상태를, 다음부터 이전 디코더 상태로 초기화\n",
        "        decoder_outputs, state_h, state_c = decoder_model.predict(\n",
        "                                                [target_seq] + states)\n",
        "\n",
        "        # 결과의 원핫인코딩 형식을 인덱스로 변환\n",
        "        index = np.argmax(decoder_outputs[0, 0, :])\n",
        "        indexs.append(index)\n",
        "        \n",
        "        # 종료 검사\n",
        "        if index == END_INDEX or len(indexs) >= max_sequences:\n",
        "            break\n",
        "\n",
        "        # 목표 시퀀스를 바로 이전의 출력으로 설정\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = index\n",
        "        \n",
        "        # 디코더의 이전 상태를 다음 디코더 예측에 사용\n",
        "        states = [state_h, state_c]\n",
        "\n",
        "    # 인덱스를 문장으로 변환\n",
        "    sentence = convert_index_to_text(indexs, index_to_word)\n",
        "        \n",
        "    return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-yMvMKS65lj"
      },
      "source": [
        "# 문장을 인덱스로 변환\n",
        "input_seq = make_predict_input('3박4일 놀러가고 싶다')\n",
        "input_seq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bu1yGFzT69v_"
      },
      "source": [
        "# 예측 모델로 텍스트 생성\n",
        "sentence = generate_text(input_seq)\n",
        "sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prt32-NR7A8H"
      },
      "source": [
        "# 문장을 인덱스로 변환\n",
        "input_seq = make_predict_input('3박4일 같이 놀러가고 싶다')\n",
        "input_seq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuZc9n0U7D8p"
      },
      "source": [
        "# 예측 모델로 텍스트 생성\n",
        "sentence = generate_text(input_seq)\n",
        "sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RY3PcNuv7F9N"
      },
      "source": [
        "# 문장을 인덱스로 변환\n",
        "input_seq = make_predict_input('오늘 기분이 꿀꿀해')\n",
        "input_seq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FXgODYZ7ItI"
      },
      "source": [
        "# 예측 모델로 텍스트 생성\n",
        "sentence = generate_text(input_seq)\n",
        "sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_QRX-qN7K42"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
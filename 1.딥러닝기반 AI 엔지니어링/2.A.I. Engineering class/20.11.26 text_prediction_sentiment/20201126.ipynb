{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20201126.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVYWJmqWZFH7"
      },
      "source": [
        "#영화 리뷰 감성 분석"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZO6UcYqIZfH7"
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1Btc6wsZXjp"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import urllib.request\n",
        "from konlpy.tag import Okt\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4O5sgCxkZblX"
      },
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", filename=\"ratings_train.txt\")\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", filename=\"ratings_test.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NNSHUo4Z20u"
      },
      "source": [
        "train_data = pd.read_table('ratings_train.txt')\n",
        "test_data = pd.read_table('ratings_test.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoSZ4S82aNfJ"
      },
      "source": [
        "print('훈련용 리뷰 개수 :',len(train_data)) # 훈련용 리뷰 개수 출력\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_ktPTuBaUNT"
      },
      "source": [
        "train_data[:5] # 상위 5개 출력\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpU49mA9aXth"
      },
      "source": [
        "print('테스트용 리뷰 개수 :',len(test_data)) # 테스트용 리뷰 개수 출력"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KmpRvbnaf5I"
      },
      "source": [
        "train_data['document'].nunique(), train_data['label'].nunique()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zlz0NnSpalnv"
      },
      "source": [
        "train_data.drop_duplicates(subset=['document'], inplace=True) # document 열에서 중복인 내용이 있다면 중복 제거"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLfriCuDa2yG"
      },
      "source": [
        "print('총 샘플의 수 :',len(train_data))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2F7uS0Da51I"
      },
      "source": [
        "train_data['label'].value_counts().plot(kind = 'bar')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxEDj0K8a8uG"
      },
      "source": [
        "print(train_data.groupby('label').size().reset_index(name = 'count'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7C6GCESobabj"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xv6mU_RCbBxS"
      },
      "source": [
        "print(train_data.isnull().values.any())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLVFSTEabbho"
      },
      "source": [
        "print(train_data.isnull().sum())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjaNA5sGbdd9"
      },
      "source": [
        "train_data.loc[train_data.document.isnull()]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RB2P-vQbgTn"
      },
      "source": [
        "train_data = train_data.dropna(how = 'any') # Null 값이 존재하는 행 제거\n",
        "print(train_data.isnull().values.any()) # Null 값이 존재하는지 확인"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCKhH7HSblut"
      },
      "source": [
        "text = 'do!!! you expect... people~ to~ read~ the FAQ, etc. and actually accept hard~! atheism?@@'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySJ3QAaubuqb"
      },
      "source": [
        "re.sub('[^a-zA-Z ]', '', text) #알파벳과 공백을 제외하고 모두 제거"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lzygx3R8bz7p"
      },
      "source": [
        "train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
        "# 한글과 공백을 제외하고 모두 제거\n",
        "train_data[:5]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fwq5kpISb-Dq"
      },
      "source": [
        "train_data['document'].replace('', np.nan, inplace=True)\n",
        "print(train_data.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kb2Ubv-8cN7n"
      },
      "source": [
        "train_data.loc[train_data.document.isnull()][:5]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDaaTV-YcQi3"
      },
      "source": [
        "train_data = train_data.dropna(how = 'any')\n",
        "print(len(train_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnOqSTyccZ7T"
      },
      "source": [
        "test_data.drop_duplicates(subset = ['document'], inplace=True) # document 열에서 중복인 내용이 있다면 중복 제거\n",
        "test_data['document'] = test_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\") # 정규 표현식 수행\n",
        "test_data['document'].replace('', np.nan, inplace=True) # 공백은 Null 값으로 변경\n",
        "test_data = test_data.dropna(how='any') # Null 값 제거\n",
        "print('전처리 후 테스트용 샘플의 개수 :',len(test_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "in8JrPdbcc_V"
      },
      "source": [
        "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkoTXeeouRYI"
      },
      "source": [
        "okt = Okt()\n",
        "okt.morphs('와 이런 것도 영화라고 차라리 뮤직비디오를 만드는 게 나을 뻔', stem = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-OQIJSruVW2"
      },
      "source": [
        "train_data['document']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kl-EibVzuoln"
      },
      "source": [
        "X_train = []\n",
        "for sentence in train_data['document']:\n",
        "    temp_X = []\n",
        "    temp_X = okt.morphs(sentence, stem=True) # 토큰화\n",
        "    temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
        "    X_train.append(temp_X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19CPDdgkuzlq"
      },
      "source": [
        "X_test = []\n",
        "for sentence in test_data['document']:\n",
        "    temp_X = []\n",
        "    temp_X = okt.morphs(sentence, stem=True) # 토큰화\n",
        "    temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
        "    X_test.append(temp_X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40JqqdpSvEB-"
      },
      "source": [
        "##불용어 제거, 토큰화\n",
        "##정수 인코딩"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rf20MpDrvLUK"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIOpjsSqvZlB"
      },
      "source": [
        "print(tokenizer.word_index)\n",
        "#빈도수가 가장 높은 단어부터 순서대로 인덱스가 부여"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8Rgc6REvdUK"
      },
      "source": [
        "#빈도수가 3회 미만인 단어들 비율 확인"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Agwga_5ev4oR"
      },
      "source": [
        "threshold = 5\n",
        "total_cnt = len(tokenizer.word_index) # 단어의 수"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yO2Vt51zv4z7"
      },
      "source": [
        "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
        "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
        "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y15LKEOnz-Qy"
      },
      "source": [
        "X_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJj4tOuSwLi8"
      },
      "source": [
        "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
        "for key, value in tokenizer.word_counts.items():\n",
        "    total_freq = total_freq + value\n",
        "\n",
        "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
        "    if(value < threshold):\n",
        "        rare_cnt = rare_cnt + 1\n",
        "        rare_freq = rare_freq + value\n",
        "\n",
        "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
        "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
        "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
        "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eUlG5Eiwtj5"
      },
      "source": [
        "vocab_size = total_cnt - rare_cnt+2 #0 번 패딩 토큰, 1번 oov  2번부터 사용\n",
        "print('단어 집합의 크기 :',vocab_size) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7e6f9TgT0ZTs"
      },
      "source": [
        "tokenizer = Tokenizer(vocab_size, oov_token = 'OOV') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVYeqM530a6n"
      },
      "source": [
        "tokenizer.fit_on_texts(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRbPywtRypnA"
      },
      "source": [
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0e5K_bfzveB"
      },
      "source": [
        "y_train = np.array(train_data['label'])\n",
        "y_test = np.array(test_data['label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAtJpa2t1JTJ"
      },
      "source": [
        "drop_train = [index for index, sentence in enumerate(X_train) if len(sentence) < 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nxxtmv221T0i"
      },
      "source": [
        "# 빈 샘플들을 제거\n",
        "X_train = np.delete(X_train, drop_train, axis=0)\n",
        "y_train = np.delete(y_train, drop_train, axis=0)\n",
        "print(len(X_train))\n",
        "print(len(y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GUBxIQ_1X0a"
      },
      "source": [
        "#패딩...데이터의 길이를 동일하게\n",
        "print('리뷰의 최대 길이 :',max(len(l) for l in X_train))\n",
        "print('리뷰의 평균 길이 :',sum(map(len, X_train))/len(X_train))\n",
        "plt.hist([len(s) for s in X_train], bins=50)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIdoeVMt1meD"
      },
      "source": [
        "def below_threshold_len(max_len, nested_list):\n",
        "  cnt = 0\n",
        "  for s in nested_list:\n",
        "    if(len(s) <= max_len):\n",
        "        cnt = cnt + 1\n",
        "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2W8XXygk1xgf"
      },
      "source": [
        "max_len = 30\n",
        "below_threshold_len(max_len, X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7B6t5Rcm1zdp"
      },
      "source": [
        "#일괄적으로 길이를 30으로\n",
        "X_train = pad_sequences(X_train, maxlen = max_len)\n",
        "X_test = pad_sequences(X_test, maxlen = max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WglXybK-2B-K"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8ok6AeZ2OvL"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 100)) #임베딩 벡터의 차원을 100차원으로...\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnM4gRvd2WTJ"
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOsJQ87r32W1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgQEL5gv2j_b"
      },
      "source": [
        "# from keras.callbacks import ModelCheckpoint 학습을 하면서 조건을 만족하면 모델의 가중치값을 중간 저장\n",
        "\n",
        "# filename = 'checkpoint-epoch-{}-batch-{}-trial-001.h5'.format(EPOCH, BATCH_SIZE)\n",
        "# checkpoint = ModelCheckpoint(filename,             # file명을 지정합니다\n",
        "#                              monitor='val_loss',   # val_loss 값이 개선되었을때 호출됩니다\n",
        "#                              verbose=1,            # 로그를 출력합니다\n",
        "#                              save_best_only=True,  # 가장 best 값만 저장합니다\n",
        "#                              mode='auto'           # auto는 알아서 best를 찾습니다. min/max\n",
        "#                             )\n",
        "\n",
        "# model.fit(x_train, y_train, \n",
        "#       validation_data=(x_valid, y_valid),\n",
        "#       epochs=EPOCH, \n",
        "#       batch_size=BATCH_SIZE, \n",
        "#       callbacks=[checkpoint], # checkpoint 콜백\n",
        "#      )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wN32x9vL36d4"
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "history = model.fit(X_train, y_train, epochs=15, callbacks=[es, mc], batch_size=60, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcHnlyWK36xZ"
      },
      "source": [
        "loaded_model = load_model('best_model.h5')\n",
        "print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFfjlbxE8OWO"
      },
      "source": [
        "def sentiment_predict(new_sentence):\n",
        "  new_sentence = okt.morphs(new_sentence, stem=True) # 토큰화\n",
        "  new_sentence = [word for word in new_sentence if not word in stopwords] # 불용어 제거\n",
        "  encoded = tokenizer.texts_to_sequences([new_sentence]) # 정수 인코딩\n",
        "  pad_new = pad_sequences(encoded, maxlen = max_len) # 패딩\n",
        "  score = float(loaded_model.predict(pad_new)) # 예측\n",
        "  if(score > 0.5):\n",
        "    print(\"{:.2f}% 확률로 긍정 리뷰입니다.\\n\".format(score * 100))\n",
        "  else:\n",
        "    print(\"{:.2f}% 확률로 부정 리뷰입니다.\\n\".format((1 - score) * 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlOFl_mO8UmX"
      },
      "source": [
        "sentiment_predict('이 영화 개꿀잼 ㅋㅋㅋ')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TduFc1568VvI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # 데이터프레임 사용을 위해\n",
    "from math import log # IDF 계산을 위해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "  '먹고 싶은 사과',\n",
    "  '먹고 싶은 바나나',\n",
    "  '길고 노란 바나나 바나나',\n",
    "  '저는 과일이 좋아요'\n",
    "] \n",
    "vocab = list(set(w for doc in docs for w in doc.split()))\n",
    "vocab.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['먹고',\n",
       " '싶은',\n",
       " '사과',\n",
       " '먹고',\n",
       " '싶은',\n",
       " '바나나',\n",
       " '길고',\n",
       " '노란',\n",
       " '바나나',\n",
       " '바나나',\n",
       " '저는',\n",
       " '과일이',\n",
       " '좋아요']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for doc in docs for w in doc.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(docs) # 총 문서의 수\n",
    "\n",
    "def tf(t, d):\n",
    "    return d.count(t)\n",
    "\n",
    "def idf(t):\n",
    "    df = 0\n",
    "    for doc in docs:\n",
    "        df += t in doc\n",
    "    return log(N/(df + 1))\n",
    "\n",
    "def tfidf(t, d):\n",
    "    return tf(t,d)* idf(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>과일이</th>\n",
       "      <th>길고</th>\n",
       "      <th>노란</th>\n",
       "      <th>먹고</th>\n",
       "      <th>바나나</th>\n",
       "      <th>사과</th>\n",
       "      <th>싶은</th>\n",
       "      <th>저는</th>\n",
       "      <th>좋아요</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   과일이  길고  노란  먹고  바나나  사과  싶은  저는  좋아요\n",
       "0    0   0   0   1    0   1   1   0    0\n",
       "1    0   0   0   1    1   0   1   0    0\n",
       "2    0   1   1   0    2   0   0   0    0\n",
       "3    1   0   0   0    0   0   0   1    1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "for i in range(N): # 각 문서에 대해서 아래 명령을 수행 4번\n",
    "    result.append([])\n",
    "    d = docs[i]\n",
    "    for j in range(len(vocab)): #9번\n",
    "        t = vocab[j]        \n",
    "        result[-1].append(tf(t, d))\n",
    "\n",
    "tf_ = pd.DataFrame(result, columns = vocab)\n",
    "tf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>과일이</th>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>길고</th>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>노란</th>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>먹고</th>\n",
       "      <td>0.287682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>바나나</th>\n",
       "      <td>0.287682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>사과</th>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>싶은</th>\n",
       "      <td>0.287682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>저는</th>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>좋아요</th>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          IDF\n",
       "과일이  0.693147\n",
       "길고   0.693147\n",
       "노란   0.693147\n",
       "먹고   0.287682\n",
       "바나나  0.287682\n",
       "사과   0.693147\n",
       "싶은   0.287682\n",
       "저는   0.693147\n",
       "좋아요  0.693147"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "for j in range(len(vocab)):\n",
    "    t = vocab[j]\n",
    "    result.append(idf(t))\n",
    "\n",
    "idf_ = pd.DataFrame(result, index = vocab, columns = [\"IDF\"])\n",
    "idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>과일이</th>\n",
       "      <th>길고</th>\n",
       "      <th>노란</th>\n",
       "      <th>먹고</th>\n",
       "      <th>바나나</th>\n",
       "      <th>사과</th>\n",
       "      <th>싶은</th>\n",
       "      <th>저는</th>\n",
       "      <th>좋아요</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.287682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.287682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.287682</td>\n",
       "      <td>0.287682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.287682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.575364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        과일이        길고        노란        먹고       바나나        사과        싶은  \\\n",
       "0  0.000000  0.000000  0.000000  0.287682  0.000000  0.693147  0.287682   \n",
       "1  0.000000  0.000000  0.000000  0.287682  0.287682  0.000000  0.287682   \n",
       "2  0.000000  0.693147  0.693147  0.000000  0.575364  0.000000  0.000000   \n",
       "3  0.693147  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "         저는       좋아요  \n",
       "0  0.000000  0.000000  \n",
       "1  0.000000  0.000000  \n",
       "2  0.000000  0.000000  \n",
       "3  0.693147  0.693147  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "for i in range(N):\n",
    "    result.append([])\n",
    "    d = docs[i]\n",
    "    for j in range(len(vocab)):\n",
    "        t = vocab[j]\n",
    "\n",
    "        result[-1].append(tfidf(t,d))\n",
    "\n",
    "tfidf_ = pd.DataFrame(result, columns = vocab)\n",
    "tfidf_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사이킷런을 이용한 DTM과 TF-IDF 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 1 0 1 0 1 1]\n",
      " [0 0 1 0 0 0 0 1 0]\n",
      " [1 0 0 0 1 0 1 0 0]]\n",
      "{'you': 7, 'know': 1, 'want': 5, 'your': 8, 'love': 3, 'like': 2, 'what': 6, 'should': 4, 'do': 0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = [\n",
    "    'you know I want your love',\n",
    "    'I like you',\n",
    "    'what should I do ',    \n",
    "]\n",
    "vector = CountVectorizer()\n",
    "print(vector.fit_transform(corpus).toarray()) # 코퍼스로부터 각 단어의 빈도 수를 기록한다.\n",
    "print(vector.vocabulary_) # 각 단어의 인덱스가 어떻게 부여되었는지를 보여준다.\n",
    "#dtm (document term matrix 생성)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DTM이 완성되었습니다. DTM에서 각 단어의 인덱스가 어떻게 부여되었는지를 확인하기 위해, 인덱스를 확인해보았습니다. 첫번째 열의 경우에는 0의 인덱스를 가진 do입니다. do는 세번째 문서에만 등장했기 때문에, 세번째 행에서만 1의 값을 가집니다. 두번째 열의 경우에는 1의 인덱스를 가진 know입니다. know는 첫번째 문서에만 등장했기 때문에 첫번째 행에서만 1의 값을 가집니다.\n",
    "\n",
    "사이킷런은 TF-IDF를 자동 계산해주는 TfidfVectorizer를 제공합니다. 향후 실습을 하다가 혼란이 생기지 않도록 언급하자면, 사이킷런의 TF-IDF는 위에서 배웠던 보편적인 TF-IDF 식에서 좀 더 조정된 다른 식을 사용합니다. 하지만 크게 다른 식은 아니며(IDF의 로그항의 분자에 1을 더해주며, 로그항에 1을 더해주고, TF-IDF에 L2 정규화라는 방법으로 값을 조정하는 등의 차이), 여전히 TF-IDF가 가진 의도를 그대로 갖고 있으므로 사이킷런의 TF-IDF를 그대로 사용하셔도 좋습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.46735098 0.         0.46735098 0.         0.46735098\n",
      "  0.         0.35543247 0.46735098]\n",
      " [0.         0.         0.79596054 0.         0.         0.\n",
      "  0.         0.60534851 0.        ]\n",
      " [0.57735027 0.         0.         0.         0.57735027 0.\n",
      "  0.57735027 0.         0.        ]]\n",
      "{'you': 7, 'know': 1, 'want': 5, 'your': 8, 'love': 3, 'like': 2, 'what': 6, 'should': 4, 'do': 0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = [\n",
    "    'you know I want your love',\n",
    "    'I like you',\n",
    "    'what should I do ',    \n",
    "]\n",
    "tfidfv = TfidfVectorizer().fit(corpus) #min_df/analyzer='char' option 사용해볼수 있다.\n",
    "print(tfidfv.transform(corpus).toarray())\n",
    "print(tfidfv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "{'you': 0}\n"
     ]
    }
   ],
   "source": [
    "tfidfv = TfidfVectorizer(min_df=2).fit(corpus) #min_df/analyzer='char' option 사용해볼수 있다.\n",
    "print(tfidfv.transform(corpus).toarray())\n",
    "print(tfidfv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.54522682 0.14041576 0.         0.14041576 0.         0.10904536\n",
      "  0.14041576 0.10904536 0.3692597  0.43618145 0.18462985 0.\n",
      "  0.14041576 0.21809073 0.18462985 0.28083152 0.28083152]\n",
      " [0.50040087 0.         0.         0.32217861 0.         0.50040087\n",
      "  0.32217861 0.25020043 0.         0.25020043 0.         0.\n",
      "  0.         0.25020043 0.         0.         0.32217861]\n",
      " [0.54546812 0.17559738 0.4617789  0.         0.4617789  0.13636703\n",
      "  0.         0.13636703 0.         0.27273406 0.         0.23088945\n",
      "  0.17559738 0.13636703 0.         0.17559738 0.        ]]\n",
      "{'y': 16, 'o': 9, 'u': 13, ' ': 0, 'k': 6, 'n': 8, 'w': 15, 'i': 5, 'a': 1, 't': 12, 'r': 10, 'l': 7, 'v': 14, 'e': 3, 'h': 4, 's': 11, 'd': 2}\n"
     ]
    }
   ],
   "source": [
    "tfidfv = TfidfVectorizer(analyzer='char').fit(corpus) #min_df/analyzer='char' option 사용해볼수 있다.\n",
    "print(tfidfv.transform(corpus).toarray())\n",
    "print(tfidfv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.34142622 0.34142622 0.         0.         0.34142622\n",
      "  0.         0.         0.34142622 0.34142622 0.         0.\n",
      "  0.25966344 0.34142622 0.34142622 0.34142622]\n",
      " [0.         0.         0.         0.62276601 0.62276601 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.4736296  0.         0.         0.        ]\n",
      " [0.4472136  0.         0.         0.         0.         0.\n",
      "  0.4472136  0.4472136  0.         0.         0.4472136  0.4472136\n",
      "  0.         0.         0.         0.        ]]\n",
      "{'you': 12, 'know': 1, 'want': 8, 'your': 14, 'love': 5, 'you know': 13, 'know want': 2, 'want your': 9, 'your love': 15, 'like': 3, 'like you': 4, 'what': 10, 'should': 6, 'do': 0, 'what should': 11, 'should do': 7}\n"
     ]
    }
   ],
   "source": [
    "tfidfv = TfidfVectorizer(ngram_range=(1,2)).fit(corpus) #min_df/analyzer='char' option 사용해볼수 있다.\n",
    "print(tfidfv.transform(corpus).toarray())\n",
    "print(tfidfv.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 옵션을 주어서 의도하는 모델을 만들어 내야한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 유클리디안 거리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 문서와 [2 3 0 1] 사이 거리 :  2.23606797749979\n",
      "입력 문서와 [1 2 3 1] 사이 거리 :  3.1622776601683795\n",
      "입력 문서와 [2 1 2 2] 사이 거리 :  2.449489742783178\n"
     ]
    }
   ],
   "source": [
    "# euclidean\n",
    "docs = [doc1,doc2,doc3]\n",
    "\n",
    "for doc in docs:\n",
    "    dist = np.sqrt(np.square(np.abs(docInput - doc)).sum())\n",
    "    print(f'입력 문서와 {doc} 사이 거리 : ',dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 코사인 유사도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "def cos_sim(A, B):\n",
    "       return dot(A, B)/(norm(A)*norm(B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cos_sim(a,b):\n",
    "    return dot(a,b) / (norm(a)*norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1=np.array([2,3,0,1])\n",
    "doc2=np.array([1,2,3,1])\n",
    "doc3=np.array([2,1,2,2])\n",
    "docInput=np.array((1,1,0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 0 1]와 [1 1 0 1]의 코사인유사도: 0.9258200997725515\n",
      "[1 2 3 1]와 [1 1 0 1]의 코사인유사도: 0.5962847939999439\n",
      "[2 1 2 2]와 [1 1 0 1]의 코사인유사도: 0.8006407690254358\n"
     ]
    }
   ],
   "source": [
    "# cosine similarity\n",
    "docs = [doc1,doc2,doc3]\n",
    "\n",
    "for doc in docs:\n",
    "    similarity = cos_sim(docInput, doc)\n",
    "    print(f'{doc}와 {docInput}의 코사인유사도:', similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 자카드 유사도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자카드 유사도 알고리즘\n",
    "교(집합): 두 집합에서 공통으로 가지고 있는 원소 집합\n",
    "합(집합): 두 집합에서 가지고 있는 원소 집합\n",
    "합집합에서 교집합의 비율을 구하자. => 두 문서의 유사도\n",
    "\n",
    "A와 B 두개의 집합이 있다고 합시다. 이때 교집합은 두 개의 집합에서 공통으로 가지고 있는 원소들의 집합을 말합니다. 즉, 합집합에서 교집합의 비율을 구한다면 두 집합 A와 B의 유사도를 구할 수 있다는 것이 자카드 유사도(jaccard similarity)의 아이디어입니다. 자카드 유사도는 0과 1사이의 값을 가지며, 만약 두 집합이 동일하다면 1의 값을 가지고, 두 집합의 공통 원소가 없다면 0의 값을 갖습니다. 자카드 유사도를 구하는 함수를 J\n",
    "라고 하였을 때, 자카드 유사도 함수 J\n",
    "는 아래와 같습니다.  \n",
    "\n",
    "J(doc1, doc2) = (doc1 교 doc2) / (doc1 합 doc2)\n",
    "\n",
    "$$J(A,B)\\; = \\,{|A∩B|\\over|A∪B|} = {{|A∩B|}\\over{|A|+|B|−|A∩B|}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple', 'banana', 'everyone', 'like', 'likey', 'watch', 'card', 'holder']\n",
      "['apple', 'banana', 'coupon', 'passport', 'love', 'you']\n"
     ]
    }
   ],
   "source": [
    "# 다음과 같은 두 개의 문서가 있습니다.\n",
    "# 두 문서 모두에서 등장한 단어는 apple과 banana 2개.\n",
    "doc1 = \"apple banana everyone like likey watch card holder\"\n",
    "doc2 = \"apple banana coupon passport love you\"\n",
    "\n",
    "# 토큰화를 수행합니다.\n",
    "tokenized_doc1 = doc1.split()\n",
    "tokenized_doc2 = doc2.split()\n",
    "\n",
    "# 토큰화 결과 출력\n",
    "print(tokenized_doc1)\n",
    "print(tokenized_doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'like', 'banana', 'apple', 'coupon', 'everyone', 'love', 'card', 'you', 'holder', 'likey', 'passport', 'watch'}\n"
     ]
    }
   ],
   "source": [
    "union = set(tokenized_doc1).union(set(tokenized_doc2))\n",
    "print(union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'apple', 'banana'}\n"
     ]
    }
   ],
   "source": [
    "intersection = set(tokenized_doc1).intersection(set(tokenized_doc2))\n",
    "print(intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "print(len(intersection)/len(union)) # 2를 12로 나눔."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 영화 추천시스템 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata\n",
    "- 데이터를 설명해주거나 꾸며주는 데이터를 메타데이터라고 한다.\n",
    "- 영화에대한 이해를 돕기위한 데이터\n",
    "- 유트브영상이 데이터라면, 메다데이터는 영상의 설명이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"movies_metadata.csv\", low_memory=False)\n",
    "#low_memory : 데이터를 읽을때, 데이터의 컬럼에대해 타입이 무엇이다 예측을한다. 그 작업을 하지 않기위해 하는 옵션설정이다.\n",
    "#대용량의 텍스트 데이터를 읽을때 활용하면 좋다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45466 entries, 0 to 45465\n",
      "Data columns (total 24 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   adult                  45466 non-null  object \n",
      " 1   belongs_to_collection  4494 non-null   object \n",
      " 2   budget                 45466 non-null  object \n",
      " 3   genres                 45466 non-null  object \n",
      " 4   homepage               7782 non-null   object \n",
      " 5   id                     45466 non-null  object \n",
      " 6   imdb_id                45449 non-null  object \n",
      " 7   original_language      45455 non-null  object \n",
      " 8   original_title         45466 non-null  object \n",
      " 9   overview               44512 non-null  object \n",
      " 10  popularity             45461 non-null  object \n",
      " 11  poster_path            45080 non-null  object \n",
      " 12  production_companies   45463 non-null  object \n",
      " 13  production_countries   45463 non-null  object \n",
      " 14  release_date           45379 non-null  object \n",
      " 15  revenue                45460 non-null  float64\n",
      " 16  runtime                45203 non-null  float64\n",
      " 17  spoken_languages       45460 non-null  object \n",
      " 18  status                 45379 non-null  object \n",
      " 19  tagline                20412 non-null  object \n",
      " 20  title                  45460 non-null  object \n",
      " 21  video                  45460 non-null  object \n",
      " 22  vote_average           45460 non-null  float64\n",
      " 23  vote_count             45460 non-null  float64\n",
      "dtypes: float64(4), object(20)\n",
      "memory usage: 8.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 공분산, 분산\n",
    "0 <= 피어슨 상관계수 (x,y) = Covariance(x,y) / (std(x)*std(y)) <= 1  \n",
    "Covariance(x,y) = (Xi-Xmean) * (Yi-Ymean)    \n",
    "variance(x)= sum((Xi - Xmean)**2) / n  \n",
    "std(x) = sqrt(variance(x))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.head(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 24)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Led by Woody, Andy's toys live happily in his ...\n",
       "1        When siblings Judy and Peter discover an encha...\n",
       "2        A family wedding reignites the ancient feud be...\n",
       "3        Cheated on, mistreated and stepped on, the wom...\n",
       "4        Just when George Banks has recovered from his ...\n",
       "                               ...                        \n",
       "19995    Dissidents in a French colony attack a police ...\n",
       "19996    A young mother Nina and her son Enzo find them...\n",
       "19997    An in-depth analysis of the relationship betwe...\n",
       "19998    Follows the life and work of animator Lotte Re...\n",
       "19999    An in-depth look at the genesis, production, a...\n",
       "Name: overview, Length: 20000, dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['overview']\n",
    "#전처리 생략"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.overview.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['overview'] = data['overview'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.overview.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 47487)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tfidf\n",
    "tfidfMat=TfidfVectorizer(stop_words='english')\n",
    "tfidfMat=tfidfMat.fit_transform(data['overview']) #여기서는 data['overview']가 코퍼스임\n",
    "tfidfMat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "연습문제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]]\n",
      "0.5036643709879097\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 47487)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tfidfMat[0].toarray())\n",
    "print(np.max(tfidfMat[0].toarray()[0])) #특정 단어의 tfidf값\n",
    "tfidfMat[0].toarray().shape\n",
    "# np.max(tfidfMat[0].toarray()[0])) 에서나온 0.503(tfidf값)에 해당하는\n",
    "# 단어가 무엇인지? 인덱스는 몇번인덱스인지? 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'buzz'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = tfidfMat[0].toarray().argmax() #최대 tidif값에 해당되는 단어의 index\n",
    "\n",
    "vocab = TfidfVectorizer(stop_words = 'english').fit(data['overview']).vocabulary_\n",
    "\n",
    "[key for key, value in vocab.items() if value == idx][0]\n",
    "#최대 tfidf값의 인덱스와 일치할경우 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "해당 단어 :  buzz\n"
     ]
    }
   ],
   "source": [
    "# 퀴즈 2 , 0.5036... 에 해당되는 단어 출력\n",
    "\n",
    "word_index_dict = TfidfVectorizer(stop_words='english').fit(data['overview']).vocabulary_\n",
    "index_word_dict = sorted(word_index_dict.items(),key=lambda x:x[1])\n",
    "\n",
    "idx = np.argmax(tfidfMat[0].toarray()[0])\n",
    "print(f'해당 단어 : ',index_word_dict[idx][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim = linear_kernel(tfidfMat, tfidfMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 20000)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000,)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim[0].shape #자기자신에대한 모든 영화와의 코사인 유사도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title\n",
      "Toy Story                      0\n",
      "Jumanji                        1\n",
      "Grumpier Old Men               2\n",
      "Waiting to Exhale              3\n",
      "Father of the Bride Part II    4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#최대값에 해당하는 영화제목 추출\n",
    "#테이블의 용도는 영화의 타이틀을 입력하면 인덱스를 리턴하기 위함\n",
    "indices = pd.Series(data.index, index=data['title']).drop_duplicates()\n",
    "print(indices.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(title, cos_sim=cos_sim):\n",
    "    # 선택한 영화의 타이틀로부터 해당되는 인덱스를 받아옵니다. 이제 선택한 영화를 가지고 연산할 수 있습니다.\n",
    "    idx = indices[title]\n",
    "\n",
    "    # 모든 영화에 대해서 해당 영화와의 유사도를 구합니다.\n",
    "    sim_scores = list(enumerate(cos_sim[idx]))\n",
    "\n",
    "    # 유사도에 따라 영화들을 정렬합니다.\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # 가장 유사한 10개의 영화를 받아옵니다.\n",
    "    sim_scores = sim_scores[1:11]\n",
    "\n",
    "    # 가장 유사한 10개의 영화의 인덱스를 받아옵니다.\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # 가장 유사한 10개의 영화의 제목을 리턴합니다.\n",
    "    return data['title'].iloc[movie_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12481                            The Dark Knight\n",
       "150                               Batman Forever\n",
       "1328                              Batman Returns\n",
       "15511                 Batman: Under the Red Hood\n",
       "585                                       Batman\n",
       "9230          Batman Beyond: Return of the Joker\n",
       "18035                           Batman: Year One\n",
       "19792    Batman: The Dark Knight Returns, Part 1\n",
       "3095                Batman: Mask of the Phantasm\n",
       "10122                              Batman Begins\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations('The Dark Knight Rises')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "퀴즈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12481                            The Dark Knight\n",
       "150                               Batman Forever\n",
       "1328                              Batman Returns\n",
       "15511                 Batman: Under the Red Hood\n",
       "585                                       Batman\n",
       "9230          Batman Beyond: Return of the Joker\n",
       "18035                           Batman: Year One\n",
       "19792    Batman: The Dark Knight Returns, Part 1\n",
       "3095                Batman: Mask of the Phantasm\n",
       "10122                              Batman Begins\n",
       "4363                                Criminal Law\n",
       "6042                                       Q & A\n",
       "11753                                  Slow Burn\n",
       "1491                              Batman & Robin\n",
       "13838                  The File on Thelma Jordon\n",
       "1353                    Night Falls on Manhattan\n",
       "12289                                   Ricochet\n",
       "3267                                         JFK\n",
       "18139                           Batman and Robin\n",
       "9977        The Hitchhiker's Guide to the Galaxy\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index=indices['The Dark Knight Rises']\n",
    "\n",
    "scores= list(enumerate(cos_sim[index]))\n",
    "\n",
    "sorted_scores=sorted(scores, key=lambda x:x[1], reverse=True)\n",
    "\n",
    "sorted_movie_idx= [i[0] for i in sorted_scores]\n",
    "\n",
    "data['title'].iloc[sorted_movie_idx][1:21]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단순히 단어로만 영화의 유사도를 찾고, 유의어 동의어 처리도 되어있지않고\n",
    "\n",
    "그래서 연관성이 떨어진 영화가 나온것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumanji 와 가장 유사한 줄거리의 영화 TOP 20 : \n",
      "6166                       Brainscan\n",
      "8801                         Quintet\n",
      "17223                 The Dark Angel\n",
      "9503                       Word Wars\n",
      "13601    The Mindscape of Alan Moore\n",
      "16843                         DeVour\n",
      "8079                         Masques\n",
      "6055                Poolhall Junkies\n",
      "19726                 Wreck-It Ralph\n",
      "2486                        eXistenZ\n",
      "10892                     Stay Alive\n",
      "13711                     Rhinoceros\n",
      "1506              The Innocent Sleep\n",
      "9107                         Nirvana\n",
      "19345                       The Wave\n",
      "10703                  Grandma's Boy\n",
      "7749              The Last of Sheila\n",
      "14166                          Gamer\n",
      "12726           Battlefield Baseball\n",
      "15512                Le Pont du Nord\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "title_in = 'Jumanji'\n",
    "\n",
    "\n",
    "top20_idx = pd.Series(cos_sim[indices[title_in]]).sort_values(ascending=False)[1:21].index\n",
    "top20_idx_sort = top20_idx.sort_values()\n",
    "\n",
    "print(f'{title_in} 와 가장 유사한 줄거리의 영화 TOP 20 : ')\n",
    "print(data.title[top20_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

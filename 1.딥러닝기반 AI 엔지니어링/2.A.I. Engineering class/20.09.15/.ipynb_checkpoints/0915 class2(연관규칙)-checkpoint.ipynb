{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기계학습  \n",
    "1. 지도학습 : 문제지와 답안이 있음 (x data , y data) 모두 존재  \n",
    "\n",
    "**분류기** = classifier  \n",
    "임의의 학습기간이 주어졌을때, 합격 불합격 맞추기:  \n",
    "출석일수...공부시간...합/불  \n",
    "10.......7........합  \n",
    "8........6........합  \n",
    "2........5........불  \n",
    "...................     \n",
    "...................   \n",
    "...................  \n",
    "7........3........?  \n",
    "  \n",
    "예측 (regressor)   \n",
    "분류 (위 문제는 분류문제)  \n",
    "이런 문제를 해결할 수 있는 <U>**분류기**</U>를 만들어야함  \n",
    "\n",
    "data로 부터 기계를 학습 시켜서 classifier 또는 regressor 를 만드는것을 머신러닝이라고 한다.  \n",
    "데이터로부터 기계를 학습시켜서 예측기나 분류기를 만드는것을 머신러닝 이라고 한다.  \n",
    "\n",
    "data => Machine Learning (알고리즘 <다양함>) => [분류/예측기] = 모델\n",
    "\n",
    "data => input => MODEL => output => prediction(result)  \n",
    "\n",
    "2. 비지도학습 (y data 또는 답안이 없는경우) 의 종류중 : <U>__연관규칙__</U>이 있다. \n",
    "\n",
    "\n",
    "모든 데이터가 비지도나 지도학습 데이터에 사용될 수 있으므로 특정지을수는 없다. 바라보는 관점에 따름.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "비지도 학습 알고리즘 중  \n",
    "K-means => 클러스터링(그룹으로 나누는 작업) => 클러스터(일종의 군집: 집합) 생성  \n",
    "클러스터로부터 얻을 수 있는 정보: 선입견(해석은 data scientist가 한다) / 클러스터는 기계가 해석은 사람이한다.  \n",
    "\n",
    "새로운 데이터가 들어올경우\n",
    "클러스터1 과 2중에 거리를 구한뒤 어느 클러스터와 가까운지 파악하고, 이 데이터는 어떤 데이터다 라고 판단이 가능함.\n",
    "\n",
    "lg 데이터 전처리 pdf-> pg56   \n",
    "rules discovered = 인사이트  \n",
    "룰은 중간에 화살표로 표시한다.\n",
    "\n",
    "거래data -> ???알고리즘 -> 연관규칙생성\n",
    "apriori 알고리즘\n",
    "\n",
    "연관규칙1 에\n",
    "    {담배} -> {라이터}\n",
    "연관규칙2    \n",
    "    {라이터} -> {담배}\n",
    "순서가 바뀌었다고 같은 규칙이 아님. 서로 다른이야기임\n",
    "\n",
    "라이터를 갖고 있는 사람이 담배를 살 확률   \n",
    "담배를 갖고 있는 사람이 라이터를 살 확률  \n",
    "서로 다르다 = 다른이야기\n",
    "\n",
    "\n",
    "연관규칙 사용:  \n",
    "- 거래 데이터 특이점 파악\n",
    "- 유용한 패턴 식별  \n",
    "- DNA pattern, 단백질 서열 검색\n",
    "- 사기성 신용카드 이용\n",
    "- 통신사 변경, 동작 패턴 식별\n",
    "- ...\n",
    "\n",
    "> 마케팅 및 영업 프로모션\n",
    "{Bagels, ...} -> {Potato Chips}  \n",
    "선행 (antecedent) -> 결론(consequent)  \n",
    "potato chip의 판매 촉진을 위해서 무엇을 해야하는지 결정할 수 있다.  \n",
    "베이글 판매를 중지한다면 어떤 제품이 영향을 받는지를 유추할 수 있다.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "상품 추천 분석 기법?  \n",
    "- 1)연관규칙분석(장바구니분석) : 기존 고객의 대규모 거래 데이터 존재 -> 함께 구매가 발생하는 규칙을 발견  \n",
    "=> 고객이 특정 상품 구매시 이와 연관성이 높은 다른 상품을 추천  \n",
    "연관규칙 기반의 추천 알고리즘\n",
    "\n",
    "- 2)협업필터링 : 고객의 상품 구매 이력 데이터를 수치화 -> 추천 대상 고객 A 와 다른 고객 B에 대한  \n",
    "  상관계수 => 서로 높은 상관관계에 해당되는 고객 B가 구매한 상품중에 고객 A가 구매한적 없는  \n",
    "  상품을 고객 A 에게 추천\n",
    "  고객 AB, AC, AD, ... AZ  (가장 높은 상관이 B 고객이라고 했을때)\n",
    "\n",
    "- 3)컨텐츠 기반 추천시스템: 고객이 과거에 구매했던 상품들의 속성과 유사한 다른 상품 아이템 중에서  \n",
    "  미구매 상품을 추천(상품속성기반추천)\n",
    "  \n",
    "2번이 정확도가 더 높다 (대체적으로)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "연관규칙  \n",
    "규칙? (rules) : if 조건식 then 결과 (if A -> B)  \n",
    "연관규칙 : 특정 사건 발생 -> 함께 발생하는 또 다른 사건 간의 규칙  \n",
    "항목집합 (item set) : 전체 항목 집합으로부터 만들어 질 수 있는 모든 각각의 부분 집합  \n",
    "\n",
    "X={a,b,c}  = 2의 3승\n",
    "  2*2*2\n",
    "x의 부분집합? 공집합...전체집합\n",
    "공집합, a, b, c, ab, ac, bc, abc\n",
    "\n",
    "이마트: item 이 1만가지 => 이마트전체상품집합 = {a1, a2,...a100000} => 2의 10000승  \n",
    "만가지의 상품이 있어도 찾아낼 수 있다 (의미) => Don't worry to learn  \n",
    "연관규칙 => apriori algorithm 사용하면 be Happy => pruning(prune) 가지치기  \n",
    "\n",
    "연관규칙? 특정 항목 집합이 발생했을 때 또 다른 항목 집합이 발생하는 규칙  \n",
    "연관규칙의 예: {채소} -> {마요네즈} 꼭 한개만 올 필요가 없다.  \n",
    "        {채소, 음료} -> {마요네즈}...  \n",
    "        {채소} -> {시럽, 식초}  \n",
    "이 연관규칙들 중에서 *의미있는 연관 규칙을 발견 -> 기준(support, confidence, lift)에 부합되는 연관 규칙을 필터링\n",
    "(support, confidence, lift) 이중 특히 lift(향상도)가 중요!! 그치만 support(지지도), 와 confidence(신뢰도)가 있어야 향상도가 나온다.\n",
    "\n",
    "{땅콩} -> {맥주} 당연한 사실.. 발견했다고 할 수 없음..  \n",
    "{물티슈} -> {컵라면}? 이런 유니크한 연관규칙이 중요! 지역마다 특성이 다름  \n",
    "이런 규칙들이 지역마다 다르다.  \n",
    "\n",
    "{건전지} -> {컵라면}? 서귀포점 이마트에는 존제해도 강남점에는 없는 규칙 일 수도 있다. 지역, 환경, 경제적 특성도 다 고려  \n",
    "\n",
    "adaptive recommender system #사람이 할 수있는 일이 아니다. 2^10000승 .. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X, Y: 공통 원소가 없는 항목 집합  \n",
    "ex) X -> Y: {건전지} -> {컵라면}  \n",
    "X -> Y: if X then Y 라는 연관 규칙  \n",
    "\n",
    "N:  전체 거래 건수  \n",
    "n(X): 항목 집합 X의 거래 건수  \n",
    "n(Y): 항목 집합 Y의 거리 건수  \n",
    "\n",
    "1) 지지도? (support): 두 항목 집합 X와 Y의 지지도? 전체 거래 건수 중에서, 항목 집합 X와 Y를 모두 포함하는 거래건수의 비율\n",
    "   - 표기 ex) s(X->Y) : X를 구매하면 Y를 구매한다 라는 규칙에대한 지지도\n",
    "   s(X->Y) = X와 Y를 모두 포함하는 거래 건수 / 전체 거래 건수\n",
    "2) 신뢰도? (confidence): 항목 집합 X를 포함하는 거래(n(X)) 중에서, 항목 집합 Y를 포함하고 있는 거래의 비율 (조건부 확률)\n",
    "   - 표기 ex) c(X->Y) : X를 구매하면 Y를 구매한다 라는 규칙에대한 지지도\n",
    "   s(X->Y) = X와 Y를 모두 포함하는 거래 건수 / 항목 집합 X가 포함된 거래 건수\n",
    "3) 향상도? \n",
    "   항목 집합 X가 주어지지 않았을때의 항목집합 Y의 확률 대비\n",
    "   항목 집합 X가 주어졌을때의 항목집합 Y의 확률 증가 비율.\n",
    "   => 향상도가 1보다 크거나 (+관계), 작다면 (-관계) 우연적 기회(random chance) 보다 우수함을 의미.\n",
    "   (X와 Y가 서로 독립이면 Lift=1)\n",
    "   - 표기: ex) Lift(X->Y) : 연관규칙의 신뢰도 / 지지도 = c(X->Y) / s(Y)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "*예시 데이터* (총 5건)\n",
    "거래번호      아이템\n",
    "1           계란, 우유\n",
    "2           계란, 기저귀, 맥주, 사과\n",
    "3           우유, 기저귀, 맥주, 콜라\n",
    "4           계란, 우유, 맥주, 기저귀\n",
    "5           계란, 우유, 맥주, 콜라\n",
    "\n",
    "N=5 (전체 거래 건수)\n",
    "n(기저귀) = 3\n",
    "n({계란, 우유})= 3건 \n",
    "\n",
    "지지도 ex):\n",
    "X={계란, 맥주}, Y= {기저귀} 인경우. \n",
    "X와 Y를 모두 포함하는 거래 건수 = 2건 (거래번호 줄단위로 보아야함)\n",
    "1) 지지도 계산 (s(X->Y))\n",
    "  2 / 5 = 0.4\n",
    "  \n",
    "2) 신뢰도 계산 (c(X->Y))\n",
    "  c(X->Y) = x와 y를 모두 포함하는 거래 건수 / 항목 집합 X가 포함된 거래 건수\n",
    "  2 / 3 = 0.667\n",
    "\n",
    "3) 향상도 계산 (Lift (X -> Y)) = c(X->Y) / s(Y)\n",
    "Lift({계란, 맥주} -> {기저귀})\n",
    "s(Y): 전체 거래 중에서 Y거래 건수의 비율\n",
    "=                           (2/3)                    /       (3/5)\n",
    "= (계란, 맥주, 기저귀가 모두 포함된수/계란,맥주가 모두 포함된 수) / (기저귀건수/전체건수)\n",
    "= 0.667 / 0.6 = 1.116 (1보다 약간 큼) 우연이 아니다!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
